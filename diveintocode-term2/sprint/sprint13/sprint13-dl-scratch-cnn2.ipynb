{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint13課題 深層学習スクラッチ畳み込みニューラルネットワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】2次元畳み込み層の作成\n",
    "\n",
    "フォワードプロパゲーションの数式\n",
    "$$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$$\n",
    "\n",
    "更新式\n",
    "$$\n",
    "w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpha \\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpha \\frac{\\partial L}{\\partial b_{m}}\n",
    "$$\n",
    "\n",
    "バックプロパゲーションの数式\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s)(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$$\n",
    "\n",
    "前の層に流す誤差の数式\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1} \\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}w_{s,t,k,m}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term2/ml-scratch/model/layer.py)のpyファイルにConv2Dクラスを実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】2次元畳み込み後の出力サイズ\n",
    "$$\n",
    "N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term2/ml-scratch/utils/change_shape.py)のget_output_sizeで実装<br>\n",
    "[Conv2DやMaxPooling](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term2/ml-scratch/model/layer.py)などのクラスの中で使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最大プーリング層の作成\n",
    "$$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term2/ml-scratch/model/layer.py)のpyファイルにMaxPoolingクラスを実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】平滑化\n",
    "平滑化するためのクラスFlatten()を作成してください。\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term2/ml-scratch/model/layer.py)のpyファイルにFlattenクラスを実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】学習・推定\n",
    "作成したConv2dを使用してMNISTの分類を学習・推定してください。\n",
    "\n",
    "この段階では精度は気にせず、動くことを確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term2/ml-scratch/model/scratch_cnn2d_classifier.py)のpyファイルにScratch2dCNNClassifierクラスを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 1, 28, 28)\n",
      "(12000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#データセットの用意\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#reshape\n",
    "X_train = X_train.reshape(len(X_train), 1, 28, 28)\n",
    "X_test = X_test.reshape(len(X_test), 1, 28, 28)\n",
    "#one-hot\n",
    "eye = np.eye(len(np.unique(y_train)))\n",
    "y_train = eye[y_train]\n",
    "y_test = eye[y_test]\n",
    "\n",
    "#normalize\n",
    "X_train = X_train.astype(np.float)/255\n",
    "X_test = X_test.astype(np.float)/255\n",
    "X_train.shape\n",
    "\n",
    "#split into train, val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) \n",
    "print(X_val.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train_acc: 0.8714375, val_acc0.8705\n",
      "train loss: 0.43093932640887195, val_loss0.43093932640887195\n",
      "epoch: 1\n",
      "train_acc: 0.9168958333333334, val_acc0.9154166666666667\n",
      "train loss: 0.2781913655388082, val_loss0.2781913655388082\n",
      "epoch: 2\n",
      "train_acc: 0.9363958333333333, val_acc0.935\n",
      "train loss: 0.2119372382259603, val_loss0.2119372382259603\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "dir_str = \"../../ml-scratch/model\"\n",
    "if (dir_str not in sys.path):\n",
    "    sys.path.append(dir_str)\n",
    "\n",
    "from scratch_cnn2d_classifier import Scratch2dCNNClassifier\n",
    "cnn = Scratch2dCNNClassifier(\n",
    "    conv_param={'n_filters': 30, 'filter_size': 5, 'stride': 1, 'pad': 0},\n",
    "    pool_param={'pool_size': 2},\n",
    "    n_epochs=3,\n",
    "    batch_size=1000,\n",
    "    optimizer='Adam',\n",
    "    optimizer_param={'lr': 0.001},\n",
    "    layer_nodes = {'hidden': 100, 'output': 10},\n",
    "    weight_init_std=0.01,\n",
    "    verbose=True\n",
    ")\n",
    "cnn.fit(x_train=X_train, y_train=y_train, x_val=X_val, y_val=y_val)\n",
    "pred = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [7 2 1 ... 4 5 6]\n",
      "actual:  [7 2 1 ... 4 5 6]\n",
      "acuracy:  0.9405\n"
     ]
    }
   ],
   "source": [
    "y_actual = np.argmax(y_test, axis=1)\n",
    "print(\"pred: \", pred)\n",
    "print(\"actual: \", y_actual)\n",
    "print(\"acuracy: \", (pred == y_actual).sum() / len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】（アドバンス課題）LeNet\n",
    "CNNで画像認識を行う際は、フィルタサイズや層の数などを１から考えるのではなく、有名な構造を利用することが一般的です。\n",
    "\n",
    "現在では実用的に使われることはありませんが、歴史的に重要なのは1998年のLeNetです。この構造を再現して動かしてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】（アドバンス課題）有名な画像認識モデルの調査\n",
    "CNNの代表的な構造としてははAlexNet(2012)、VGG16(2014)などがあります。こういったものはフレームワークで既に用意されていることも多いです。\n",
    "\n",
    "どういったものがあるか簡単に調べてまとめてください。名前だけでも見ておくと良いでしょう。\n",
    "\n",
    "参考\n",
    "\n",
    "Applications - Keras Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】（アドバンス課題）平均プーリングの作成\n",
    "平均プーリング層のクラスAveragePool2Dを作成してください。\n",
    "\n",
    "範囲内の最大値ではなく、平均値を出力とするプーリング層です。\n",
    "\n",
    "画像認識関係では最大プーリング層が一般的で、平均プーリングはあまり使われません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題9】出力サイズとパラメータ数の計算\n",
    "CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。\n",
    "\n",
    "また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。\n",
    "\n",
    "以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。\n",
    "＊最後の例は丁度良く畳み込みをすることができない場合です。フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。端が欠けてしまうので、こういった設定は好ましくないという例です。\n",
    "\n",
    "1.<br>\n",
    "\n",
    "入力サイズ : 144×144, 3チャンネル<br>\n",
    "フィルタサイズ : 3×3, 6チャンネル<br>\n",
    "ストライド : 1<br>\n",
    "パディング : なし<br>\n",
    "<br>\n",
    "畳み込み層の出力サイズ: <br>\n",
    "1 +(144 + 2*0 - 3)/1 = 142より142^2のサイズで6 channel<br>\n",
    "パラメータ数: <br>\n",
    "filter_size * num_input_channels * num_filters = (3 * 3) * 3 * (6/3) = 54<br>\n",
    "バイアス項をフィルター枚数分足すと56<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "2.<br>\n",
    "入力サイズ : 60×60, 24チャンネル<br>\n",
    "フィルタサイズ : 3×3, 48チャンネル<br>\n",
    "ストライド　: 1<br>\n",
    "パディング : なし<br>\n",
    "<br>\n",
    "畳み込み層の出力サイズ: <br>\n",
    "1 +(60 + 2*0 - 3)/1 = 58より58^2のサイズで48 channel<br>\n",
    "パラメータ数: <br>\n",
    "filter_size * num_input_channels * num_filters = (3 * 3) * 24 * (48/24) = 432<br>\n",
    "バイアス項をフィルター枚数分足すと434<br>\n",
    "<br>\n",
    "3.<br>\n",
    "入力サイズ : 20×20, 10チャンネル<br>\n",
    "フィルタサイズ: 3×3, 20チャンネル<br>\n",
    "ストライド : 2<br>\n",
    "パディング : なし<br>\n",
    "<br>\n",
    "畳み込み層の出力サイズ: <br>\n",
    "1 +(20 + 2*0 - 3)/2 = 9.5 より9^2のサイズで20 channel<br>\n",
    "パラメータ数: <br>\n",
    "filter_size * num_input_channels * num_filters =  (3 * 3) * 10 * (20/10) = 180<br>\n",
    "バイアス項をフィルター枚数分足すと182<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題10】（アドバンス課題）フィルタサイズに関する調査\n",
    "畳み込み層にはフィルタサイズというハイパーパラメータがありますが、2次元畳み込み層において現在では3×3と1×1の使用が大半です。以下のそれぞれを調べたり、自分なりに考えて説明してください。\n",
    "\n",
    "7×7などの大きめのものではなく、3×3のフィルタが一般的に使われる理由\n",
    "高さや幅方向を持たない1×1のフィルタの効果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H_out = (H_in + 2P - F)/S + 1\n",
    "に関して、ストライドが1の場合\n",
    "H_out = H_in + 2P - F + 1\n",
    "となる。\n",
    "2P - F + 1が偶数の時、H_outとH_inでの画像の偶奇が不変となる。\n",
    "この時、2Pは偶数なので、-F+1が偶数（=Fが奇数）である。\n",
    "\n",
    "フィルターサイズが奇数である理由は上記のようなものだと考えられる。\n",
    "ストライドが1であるのは除算で割り切れない場合を避けているのだろうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
