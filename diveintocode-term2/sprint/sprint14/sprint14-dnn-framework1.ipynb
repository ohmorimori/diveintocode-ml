{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint14課題 ディープラーニングフレームワーク1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowを触ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseSession.close of <tensorflow.python.client.session.Session object at 0x1120c2198>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "output = sess.run(add)\n",
    "print(output)\n",
    "sess.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#こっちでも良い\n",
    "with tf.Session() as sess:\n",
    "        output = sess.run(add)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#NumPyでも同じ計算\n",
    "import numpy as np\n",
    "a_n = np.array(5)\n",
    "b_n = np.array(7)\n",
    "output_n = np.add(a_n, b_n)\n",
    "print(output_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データフロープログラミング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_8:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_9:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Add_4:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = tf.add(a, b)\n",
    "\n",
    "#numpyであれば上記で計算まで行われるがTensorFlowでは進まない\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#placeholder (data flow graph構築時には値が決まっていない)\n",
    "#variable (data flow graph構築時に値が決まっていて、変更もできる)\n",
    "#constant (data flow graph構築時に値が決まっていて、変更できない)\n",
    "\n",
    "#placeholderの使い方\n",
    "c = tf.placeholder(tf.int32)\n",
    "d = tf.placeholder(tf.int32)\n",
    "add = tf.add(c, d)\n",
    "\n",
    "sess = tf.Session()\n",
    "output = sess.run(add, feed_dict={c:5, d:7})\n",
    "sess.close\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "output = sess.run(add, feed_dict={c:20, d:32})\n",
    "sess.close\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        output_n = sess.run(add)\n",
    "        print(output_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logic Circuit\n",
    "\n",
    "|Input1|Input2|Output|\n",
    "|---|---|---|\n",
    "|0|0|0|\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|1|1|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "import numpy as np\n",
    "x_train = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "y_train = np.array([\n",
    "    [0], [0], [0], [1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Accuracy: 0.750\n",
      "epoch: 100, Accuracy: 1.000\n",
      "epoch: 200, Accuracy: 1.000\n",
      "epoch: 300, Accuracy: 1.000\n",
      "epoch: 400, Accuracy: 1.000\n",
      "epoch: 500, Accuracy: 1.000\n",
      "epoch: 600, Accuracy: 1.000\n",
      "epoch: 700, Accuracy: 1.000\n",
      "epoch: 800, Accuracy: 1.000\n",
      "epoch: 900, Accuracy: 1.000\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "[[1.9651403e-04]\n",
      " [4.9049813e-02]\n",
      " [4.9049813e-02]\n",
      " [9.3120378e-01]]\n",
      "W:  [[5.569955]\n",
      " [5.569955]]\n",
      "b:  [-8.53458]\n"
     ]
    }
   ],
   "source": [
    "#データフローグラフの構築\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "t = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "#重みとバイアスのvaliableを用意\n",
    "W= tf.Variable(tf.zeros([2, 1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "#logistic regressionの仮定関数と目的関数\n",
    "y = tf.sigmoid(tf.matmul(x, W) + b)\n",
    "cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1-y))\n",
    "\n",
    "#parameter optimization\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "#正解かどうか判定\n",
    "#tf.signで正負判定して1(positive), 0(zero), -1(negative)を返却\n",
    "#tf.equalで等しいか判定\n",
    "correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t - 0.5))\n",
    "\n",
    "#正解率\n",
    "#tf.reduce_mean()で多次元配列の各成分の平均を計算\n",
    "#tf.castでboolを0, 1に変換\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#セッションを準備してパラメータを最適化させる計算をする\n",
    "with tf.Session() as sess:\n",
    "        #tf.global_variables_initializer() でW, bを初期化\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(1000):\n",
    "                sess.run(train_step, feed_dict={x:x_train, t:y_train})\n",
    "                #100 loop毎にaccuracyを表示\n",
    "                if epoch % 100 == 0:\n",
    "                        acc_val = sess.run(accuracy, feed_dict={x:x_train, t:y_train})\n",
    "                        print(\"epoch: %d, Accuracy: %.3f\" % (epoch, acc_val))\n",
    "        #学習結果が正しいか確認\n",
    "        classified = sess.run(correct_prediction, feed_dict={x:x_train,t:y_train})\n",
    "        #出力yの確認\n",
    "        prob = sess.run(y, feed_dict={x:x_train, t:y_train})\n",
    "        \n",
    "        print(classified)\n",
    "        print(prob)\n",
    "        print(\"W: \", sess.run(W))\n",
    "        print(\"b: \", sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】スクラッチを振り返る\n",
    "ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n",
    "それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 重みを初期化する必要があった\n",
    "* エポックのループが必要だった\n",
    "* forward propagationとback propagationが必要だった。\n",
    "* activatorで次のLayerに渡す特徴量を活性化する必要があった。\n",
    "* optimizerでパラメータの更新が必要だった。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】スクラッチとTensorFlowの対応を考える\n",
    "以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n",
    "\n",
    "それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。\n",
    "\n",
    "* 重みの初期化はtf.random_normalで実施。\n",
    "* エポックのループはtensorflowではなく、for文でepoch数だけ回す\n",
    "* backward propagationはコーディング上意識する必要はなく、layerにA=XW+Bを代入して活性化関数を当てるforward側の流れのみを書けば良い。\n",
    "* activatorは「tf.nn.relu(A)」などで引数Aに値を渡せばで良い。\n",
    "* optimizerは「tf.train.Optimizer名」でインスタンスを作り、「optimizer.minimize(cost_function)」で最適化をする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mini batchをimport\n",
    "import sys\n",
    "\n",
    "dir_str = \"../../ml-scratch/utils\"\n",
    "if dir_str not in sys.path:\n",
    "        sys.path.append(dir_str)\n",
    "        \n",
    "from get_mini_batch import GetMiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def example_net(x, n_input, n_hidden1, n_hidden2, n_classes):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa']=0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "y = y.astype(np.int)\n",
    "\n",
    "#one hot encode\n",
    "eye = np.eye(len(np.unique(y)))\n",
    "y = eye[y]\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mini batchをimport\n",
    "import sys\n",
    "\n",
    "dir_str = \"../../ml-scratch/utils\"\n",
    "if dir_str not in sys.path:\n",
    "        sys.path.append(dir_str)\n",
    "        \n",
    "from get_mini_batch import GetMiniBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoidのままやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ohmori/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[[0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [9.9999988e-01 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [3.5452946e-11 1.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00]]\n",
      "[[2.6994944e-04 9.9994934e-01 1.0000000e+00]\n",
      " [1.4016032e-04 9.9120671e-01 1.0000000e+00]\n",
      " [4.5499504e-03 9.9946213e-01 1.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [3.4374952e-02 9.9999934e-01 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [9.4420682e-10 9.6970123e-12 1.0000000e+00]\n",
      " [1.1459473e-07 5.8915445e-10 1.0000000e+00]]\n",
      "[[3.1238794e-03 0.0000000e+00 1.0000000e+00]\n",
      " [2.0322192e-01 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 9.7685659e-01 1.0000000e+00]\n",
      " [1.4603138e-06 0.0000000e+00 1.0000000e+00]\n",
      " [3.6061439e-01 0.0000000e+00 1.0000000e+00]\n",
      " [9.8839033e-01 0.0000000e+00 1.0000000e+00]\n",
      " [2.5493503e-03 0.0000000e+00 1.0000000e+00]\n",
      " [1.0171294e-02 0.0000000e+00 1.0000000e+00]\n",
      " [2.5465720e-14 1.6188498e-38 1.0000000e+00]\n",
      " [4.9745409e-05 2.4612619e-35 1.0000000e+00]]\n",
      "[[3.2053739e-01 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.4594197e-04 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [6.9560814e-01 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [8.9683101e-07 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 7.1002011e-26 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.4901161e-07 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [3.5762787e-07 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.1350880e-35 1.0000000e+00]\n",
      " [5.1530731e-11 0.0000000e+00 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.1920929e-07 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.8553487e-11 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 1.]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.4494062e-24 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[1. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Epoch 0, loss : 49.0361, val_loss : 21.3904, acc : 0.500, val_acc : 0.806\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999988e-01]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 6.3180923e-06]\n",
      " [4.1049311e-31 0.0000000e+00 2.0012706e-16]\n",
      " [1.0000000e+00 0.0000000e+00 5.8145789e-30]]\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.04945193e-36]\n",
      " [4.68887252e-31 0.00000000e+00 1.11054145e-36]]\n",
      "[[0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [1.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [0.000000e+00 0.000000e+00 0.000000e+00]\n",
      " [6.094908e-29 0.000000e+00 0.000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.4657342e-36 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.8522449e-29 0.0000000e+00]\n",
      " [1.4216954e-27 4.8040936e-17 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 4.1007996e-05 0.0000000e+00]\n",
      " [0.0000000e+00 8.8512897e-06 0.0000000e+00]\n",
      " [0.0000000e+00 1.2809780e-01 0.0000000e+00]\n",
      " [0.0000000e+00 9.4137490e-03 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.5430098e-19 0.0000000e+00]\n",
      " [1.0000000e+00 3.8016067e-20 0.0000000e+00]]\n",
      "[[0.0000000e+00 9.9999827e-01 0.0000000e+00]\n",
      " [1.0000000e+00 5.0306320e-05 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0132790e-06 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.7881393e-07 0.0000000e+00]\n",
      " [0.0000000e+00 3.6001205e-05 0.0000000e+00]\n",
      " [5.9830181e-15 1.0000000e+00 2.4433860e-34]\n",
      " [1.0000000e+00 2.6647035e-08 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 9.9993998e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0728836e-06 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 9.9995160e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.1762754e-02 0.0000000e+00]\n",
      " [1.0000000e+00 9.9649787e-01 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 9.7533590e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 9.9999690e-01 0.0000000e+00]\n",
      " [1.0000000e+00 9.9805844e-01 0.0000000e+00]\n",
      " [1.0000000e+00 9.9997234e-01 0.0000000e+00]\n",
      " [1.9699182e-26 1.0000000e+00 3.0836607e-23]\n",
      " [1.0000000e+00 9.9229938e-01 0.0000000e+00]]\n",
      "[[1.        0.9013073 0.       ]\n",
      " [0.        1.        0.       ]\n",
      " [0.        1.        0.       ]\n",
      " [0.        1.        0.       ]\n",
      " [0.        1.        0.       ]\n",
      " [0.        1.        0.       ]]\n",
      "Epoch 1, loss : 5.8864, val_loss : 18.1321, acc : 0.833, val_acc : 0.653\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 9.9589503e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.1912526e-33 1.0000000e+00 6.4336775e-21]\n",
      " [1.0000000e+00 5.2408966e-05 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.0000000e+00 4.3463597e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 5.0215799e-01]\n",
      " [1.0000000e+00 8.9406967e-08 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 3.5198497e-09]\n",
      " [2.6658830e-34 1.0000000e+00 1.2441987e-09]]\n",
      "[[0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 3.1614989e-02]\n",
      " [0.0000000e+00 1.0000000e+00 1.6645879e-02]\n",
      " [0.0000000e+00 1.0000000e+00 1.0135770e-04]\n",
      " [0.0000000e+00 1.0000000e+00 9.9292976e-01]\n",
      " [0.0000000e+00 1.0000000e+00 8.0075420e-02]\n",
      " [2.4542619e-32 1.0000000e+00 9.9770015e-01]]\n",
      "[[0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 9.9376726e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 4.5148985e-20 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9985439e-01 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999988e-01 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.1275193e-01 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 3.2991171e-05 1.0000000e+00]\n",
      " [1.0000000e+00 5.5664566e-30 0.0000000e+00]\n",
      " [4.9553366e-35 1.0000000e+00 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.3113022e-06 1.0000000e+00]\n",
      " [0.0000000e+00 2.8891861e-03 1.0000000e+00]\n",
      " [0.0000000e+00 2.1236837e-03 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 2.2582609e-36 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9727619e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.1813878e-17 1.7107961e-11 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [2.0861626e-07 0.0000000e+00 1.0132790e-06]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [4.5129575e-33 9.6605435e-25 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 3.3857244e-27 1.3497103e-06]]\n",
      "Epoch 2, loss : 15.7294, val_loss : 8.1970, acc : 0.611, val_acc : 0.806\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999964e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.7164278e-37 3.4492327e-37 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9998713e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.1920929e-07]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [2.1224345e-37 1.9607795e-33 1.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 2.3841858e-07 2.4795622e-01]\n",
      " [0.0000000e+00 2.3841858e-07 3.4420717e-01]\n",
      " [0.0000000e+00 0.0000000e+00 3.9130449e-04]\n",
      " [0.0000000e+00 5.0663948e-07 9.9999952e-01]\n",
      " [0.0000000e+00 2.6530847e-23 9.9999976e-01]\n",
      " [3.9946697e-36 6.1207520e-20 1.0000000e+00]]\n",
      "[[0.0000000e+00 3.3259392e-05 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 7.7824247e-01 5.7807267e-03]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.3981631e-03 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.8977658e-07 1.0000000e+00]\n",
      " [1.0000000e+00 2.8986815e-35 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999535e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 8.9406967e-08]\n",
      " [0.0000000e+00 0.0000000e+00 2.0349026e-04]\n",
      " [0.0000000e+00 2.7004337e-01 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 2.9119849e-04 1.0000000e+00]\n",
      " [1.0000000e+00 1.9777787e-34 0.0000000e+00]\n",
      " [3.3565942e-36 1.0000000e+00 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9128997e-01 3.3622116e-02]\n",
      " [0.0000000e+00 9.9999940e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 9.9956834e-01]\n",
      " [0.0000000e+00 1.0000000e+00 8.9406967e-08]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.8198652e-05]\n",
      " [1.0000000e+00 2.2148182e-29 0.0000000e+00]\n",
      " [1.0000000e+00 4.9798460e-32 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.0000000e+00 5.9604645e-08]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999952e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0186434e-04 0.0000000e+00]\n",
      " [6.5457594e-17 1.0000000e+00 6.4376333e-20]\n",
      " [1.0000000e+00 8.5846266e-26 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [3.1411648e-05 9.9909997e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9997336e-01 9.9757385e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 9.9999702e-01]\n",
      " [1.0000000e+00 1.7868640e-25 0.0000000e+00]\n",
      " [1.0000000e+00 5.9174552e-26 0.0000000e+00]]\n",
      "[[0.0000000e+00 9.9997056e-01 9.9759805e-01]\n",
      " [0.0000000e+00 1.1920929e-07 8.6483109e-01]\n",
      " [0.0000000e+00 9.9999988e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999726e-01 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.1210668e-30 1.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 6.9452147e-23 0.0000000e+00]]\n",
      "[[1.        0.        0.       ]\n",
      " [0.        0.        0.2078946]\n",
      " [0.        1.        0.       ]\n",
      " [0.        1.        0.       ]\n",
      " [0.        1.        0.       ]\n",
      " [0.        0.9999999 0.       ]]\n",
      "Epoch 3, loss : 0.0873, val_loss : 4.1662, acc : 0.944, val_acc : 0.778\n",
      "[[0.0000000e+00 0.0000000e+00 9.9999976e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.8004179e-03 3.1790137e-04]\n",
      " [0.0000000e+00 1.4751554e-03 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 5.8475137e-04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999893e-01 1.7881393e-07]\n",
      " [5.5297410e-36 4.2105719e-09 6.6207504e-01]\n",
      " [1.0000000e+00 5.1196413e-28 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.0000000e+00 9.9993300e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 9.9947774e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999785e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.2867995e-17 1.0000000e+00]\n",
      " [8.1022125e-36 2.5576295e-12 9.9998510e-01]]\n",
      "[[0.0000000e+00 7.6669544e-02 1.0000000e+00]\n",
      " [0.0000000e+00 8.9406967e-08 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 7.3909760e-06 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 3.2037431e-07 1.2371000e-06]\n",
      " [1.1386008e-35 8.9639241e-07 9.9873966e-01]]\n",
      "[[0.0000000e+00 1.3608336e-03 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999952e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999869e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 6.1545138e-06 1.0000000e+00]\n",
      " [1.0000000e+00 2.2699408e-26 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9990749e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999762e-01 4.4703484e-07]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 6.6912048e-32 0.0000000e+00]\n",
      " [3.6668378e-34 9.9431664e-01 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 4.1691363e-03 0.0000000e+00]\n",
      " [0.0000000e+00 3.2454729e-05 7.7055007e-02]\n",
      " [0.0000000e+00 4.4405460e-06 1.0000000e+00]\n",
      " [0.0000000e+00 1.8778443e-04 9.9935436e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 3.7893924e-32 0.0000000e+00]\n",
      " [1.0000000e+00 3.4629739e-35 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999988e-01]\n",
      " [0.0000000e+00 2.4208426e-04 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.2443682e-02 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.3033772e-20 6.0368169e-02 2.1151216e-09]\n",
      " [1.0000000e+00 1.3318223e-31 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 6.8662095e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9680126e-01 2.0861626e-07]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999166e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.2759341e-31 0.0000000e+00]\n",
      " [1.0000000e+00 7.1986264e-34 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [4.0234506e-29 5.3880265e-19 1.0000000e+00]\n",
      " [1.0000000e+00 3.1248618e-28 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 9.9899697e-01 1.3679266e-05]\n",
      " [0.0000000e+00 9.9951947e-01 0.0000000e+00]\n",
      " [0.0000000e+00 7.5200200e-04 6.4496064e-01]\n",
      " [0.0000000e+00 4.8394033e-01 1.7819018e-25]]\n",
      "Epoch 4, loss : 0.4975, val_loss : 1.8053, acc : 0.833, val_acc : 0.875\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 9.9990851e-01 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [2.8654138e-35 2.7920564e-24 1.0000000e+00]\n",
      " [1.0000000e+00 6.0041367e-25 0.0000000e+00]]\n",
      "[[0.0000000e+00 9.9997926e-01 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 5.9604645e-08]\n",
      " [0.0000000e+00 9.9999976e-01 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.5196298e-26 1.0000000e+00]\n",
      " [2.6557620e-35 3.3059310e-20 1.0000000e+00]]\n",
      "[[0.0000000e+00 2.7788898e-01 1.0000000e+00]\n",
      " [0.0000000e+00 1.7881393e-07 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.1372566e-04 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 2.4616718e-05]\n",
      " [0.0000000e+00 2.6812727e-04 9.9998224e-01]\n",
      " [1.3127932e-35 5.5200526e-06 1.0000000e+00]]\n",
      "[[0.0000000e+00 9.9999994e-01 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 6.0468912e-05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9996603e-01 1.0000000e+00]\n",
      " [1.0000000e+00 4.0994569e-11 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 2.2944239e-01 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 2.6339263e-02 1.0000000e+00]\n",
      " [1.0000000e+00 5.2850914e-12 0.0000000e+00]\n",
      " [8.1051529e-35 1.0000000e+00 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.7441865e-01 9.9999976e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.4901161e-07]\n",
      " [0.0000000e+00 1.0000000e+00 9.9999928e-01]\n",
      " [0.0000000e+00 1.0000000e+00 5.2146018e-03]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 2.8675905e-12 0.0000000e+00]\n",
      " [1.0000000e+00 3.6630041e-13 0.0000000e+00]]\n",
      "[[0.0000000e+00 9.8681587e-01 7.9060221e-01]\n",
      " [1.0000000e+00 8.9406967e-08 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 2.0027161e-05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9979985e-01]\n",
      " [9.8649770e-21 1.0000000e+00 2.2622738e-18]\n",
      " [1.0000000e+00 2.6621071e-12 0.0000000e+00]]\n",
      "[[0.0000000e+00 9.9760103e-01 0.0000000e+00]\n",
      " [1.0000000e+00 5.9604645e-08 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999988e-01 1.2516975e-06]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999952e-01 1.0000000e+00]\n",
      " [1.0000000e+00 1.7635621e-14 0.0000000e+00]\n",
      " [1.0000000e+00 1.0734611e-12 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 9.9997497e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.2457848e-29 1.8879696e-07 1.0000000e+00]\n",
      " [1.0000000e+00 7.6427043e-13 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999654e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 2.2008378e-36]]\n",
      "Epoch 5, loss : 0.0000, val_loss : 1.1143, acc : 1.000, val_acc : 0.917\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9990213e-01]\n",
      " [0.0000000e+00 0.0000000e+00 3.3452511e-03]\n",
      " [0.0000000e+00 9.9999988e-01 1.7881393e-07]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999583e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 4.7797084e-02]\n",
      " [9.5800099e-36 2.1274639e-26 1.0000000e+00]\n",
      " [1.0000000e+00 5.7221530e-18 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.2837023e-02 9.9992990e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 4.6938241e-02 9.9979603e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 3.3188951e-01]\n",
      " [0.0000000e+00 1.1479513e-35 1.0000000e+00]\n",
      " [9.2727341e-36 8.8670242e-29 1.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999970e-01 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999893e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.2999075e-18 1.8817374e-07]\n",
      " [5.4758353e-36 2.6071482e-20 9.9999583e-01]]\n",
      "[[0.0000000e+00 4.0829182e-06 9.9791425e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9990880e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999988e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.6980455e-19 1.0000000e+00]\n",
      " [1.0000000e+00 8.3288724e-15 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999994e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 5.3232285e-17 0.0000000e+00]\n",
      " [2.8044565e-34 1.4107702e-02 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9986541e-01]\n",
      " [0.0000000e+00 9.9999666e-01 0.0000000e+00]\n",
      " [0.0000000e+00 9.7328210e-01 0.0000000e+00]\n",
      " [0.0000000e+00 3.5762787e-06 9.9867964e-01]\n",
      " [0.0000000e+00 6.7961276e-02 2.2888184e-05]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999976e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.3769218e-16 0.0000000e+00]\n",
      " [1.0000000e+00 5.0529229e-18 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 9.2475390e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0860562e-03 2.1189451e-05]\n",
      " [0.0000000e+00 9.9999976e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9997962e-01]\n",
      " [1.1334703e-19 1.0000000e+00 1.8376657e-18]\n",
      " [1.0000000e+00 2.4586783e-15 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.7881393e-07 6.7085028e-05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999952e-01 0.0000000e+00]\n",
      " [0.0000000e+00 6.4282793e-01 3.8403273e-04]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 2.6822090e-07 1.0000000e+00]\n",
      " [1.0000000e+00 6.3504521e-15 0.0000000e+00]\n",
      " [1.0000000e+00 1.6383875e-13 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 8.4321433e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [6.9169822e-29 1.2395400e-12 1.0000000e+00]\n",
      " [1.0000000e+00 9.8480321e-11 0.0000000e+00]]\n",
      "[[1.0000000e+00 1.1920929e-07 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999988e-01 8.9406967e-08]\n",
      " [0.0000000e+00 1.0000000e+00 2.3842783e-30]]\n",
      "Epoch 6, loss : 0.0000, val_loss : 0.9300, acc : 1.000, val_acc : 0.958\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999994e-01]\n",
      " [0.0000000e+00 1.0000000e+00 3.0515993e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 3.2085478e-03 0.0000000e+00]\n",
      " [0.0000000e+00 1.7583370e-06 1.0000000e+00]\n",
      " [2.3558924e-35 6.7605607e-23 1.0000000e+00]\n",
      " [1.0000000e+00 7.6590567e-11 0.0000000e+00]]\n",
      "[[0.0000000e+00 9.9999917e-01 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999976e-01 1.0000000e+00]\n",
      " [1.0000000e+00 1.4901161e-07 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 5.1030287e-28 1.0000000e+00]\n",
      " [2.0895313e-35 9.8040098e-22 1.0000000e+00]]\n",
      "[[0.0000000e+00 6.2406063e-05 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 8.9825988e-02 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.2243672e-06 4.8661748e-01]\n",
      " [8.1193527e-36 2.3815130e-09 1.0000000e+00]]\n",
      "[[0.0000000e+00 1.0000000e+00 9.9999958e-01]\n",
      " [1.0000000e+00 4.1251868e-02 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 2.9802322e-08]\n",
      " [1.0000000e+00 2.2053719e-06 0.0000000e+00]\n",
      " [1.0000000e+00 4.7153234e-04 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 3.6448240e-05 0.0000000e+00]\n",
      " [0.0000000e+00 1.0397186e-02 1.0000000e+00]\n",
      " [1.0000000e+00 1.4515505e-03 0.0000000e+00]]\n",
      "[[1.0000000e+00 1.9371510e-06 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 3.2782555e-07 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 2.3195860e-05 0.0000000e+00]\n",
      " [5.9716709e-35 1.0000000e+00 1.0000000e+00]]\n",
      "[[1.00000000e+00 1.40070915e-06 0.00000000e+00]\n",
      " [0.00000000e+00 5.66244125e-07 9.99999881e-01]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 2.98023224e-08]\n",
      " [0.00000000e+00 1.00000000e+00 9.99998331e-01]\n",
      " [0.00000000e+00 1.00000000e+00 4.34389710e-03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 4.54524525e-07 0.00000000e+00]\n",
      " [1.00000000e+00 1.10987806e-07 0.00000000e+00]]\n",
      "[[0.0000000e+00 4.0125847e-04 9.9245906e-01]\n",
      " [1.0000000e+00 1.6446024e-02 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.0553002e-04]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 8.9406967e-06 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999982e-01]\n",
      " [3.5318677e-20 1.0000000e+00 4.8388900e-18]\n",
      " [1.0000000e+00 4.5347583e-08 0.0000000e+00]]\n",
      "[[0.0000000e+00 1.6542256e-02 1.6489625e-04]\n",
      " [1.0000000e+00 5.2449107e-04 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999583e-01 6.3419342e-05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 7.6234341e-05 0.0000000e+00]\n",
      " [0.0000000e+00 2.9741931e-01 1.0000000e+00]\n",
      " [1.0000000e+00 9.9003888e-11 0.0000000e+00]\n",
      " [1.0000000e+00 1.7709020e-08 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 9.6745384e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.6822090e-07 0.0000000e+00]\n",
      " [5.1678292e-29 1.6604194e-12 1.0000000e+00]\n",
      " [1.0000000e+00 1.5348427e-09 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9975985e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 4.6052186e-32]]\n",
      "Epoch 7, loss : 0.0000, val_loss : 1.2199, acc : 1.000, val_acc : 0.931\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9879682e-01]\n",
      " [0.0000000e+00 9.9999535e-01 2.3692846e-05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 2.0861626e-07 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9952745e-01]\n",
      " [2.0441261e-36 2.5818269e-31 1.0000000e+00]\n",
      " [1.0000000e+00 3.4131199e-15 0.0000000e+00]]\n",
      "[[0.0000000e+00 3.1650066e-05 9.9999392e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 4.6998262e-05 9.9999374e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9990022e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.5212692e-36 7.1546663e-32 1.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999964e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.1765839e-18 1.1522874e-06]\n",
      " [7.1135036e-36 1.9878895e-21 9.9999976e-01]]\n",
      "[[0.0000000e+00 3.1810999e-04 8.1448591e-01]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999619e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 4.5639235e-19 1.0000000e+00]\n",
      " [1.0000000e+00 1.1182080e-10 0.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999976e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 7.0860163e-13 0.0000000e+00]\n",
      " [7.3726788e-35 3.7800434e-01 9.9999988e-01]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.8552030e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9998021e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.2437105e-03 2.2474676e-01]\n",
      " [0.0000000e+00 9.3517888e-01 1.7881393e-07]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999893e-01]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.2825197e-12 0.0000000e+00]\n",
      " [1.0000000e+00 6.4766701e-14 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.7044348e-01]\n",
      " [1.0000000e+00 1.1026859e-06 0.0000000e+00]\n",
      " [0.0000000e+00 6.7337459e-01 5.9604645e-08]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9988329e-01]\n",
      " [1.1354567e-19 1.0000000e+00 1.6351443e-20]\n",
      " [1.0000000e+00 1.2237194e-11 0.0000000e+00]]\n",
      "[[0.0000000e+00 3.3318996e-05 4.1216612e-05]\n",
      " [1.0000000e+00 7.5459480e-05 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9847478e-01 7.1227551e-06]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.0669231e-05 0.0000000e+00]\n",
      " [0.0000000e+00 4.7117472e-05 1.0000000e+00]\n",
      " [1.0000000e+00 1.8631645e-11 0.0000000e+00]\n",
      " [1.0000000e+00 2.0989539e-09 0.0000000e+00]]\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 9.9848020e-01 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.5497208e-06 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.1771917e-05 0.0000000e+00]\n",
      " [4.2545095e-29 1.7872244e-11 1.0000000e+00]\n",
      " [1.0000000e+00 8.9546816e-08 0.0000000e+00]]\n",
      "[[1.0000000e+00 1.0699034e-05 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 2.9351075e-30]]\n",
      "Epoch 8, loss : 0.0000, val_loss : 0.8806, acc : 1.000, val_acc : 0.958\n",
      "[[0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 4.99572754e-02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 1.13789976e-01 0.00000000e+00]\n",
      " [0.00000000e+00 2.95042992e-06 1.00000000e+00]\n",
      " [2.20352619e-36 3.69866428e-23 1.00000000e+00]\n",
      " [1.00000000e+00 2.53854782e-09 0.00000000e+00]]\n",
      "[[0.0000000e+00 9.9998647e-01 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9999452e-01 1.0000000e+00]\n",
      " [1.0000000e+00 7.4505806e-07 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 4.9154011e-29 1.0000000e+00]\n",
      " [1.8936834e-36 8.1297588e-23 1.0000000e+00]]\n",
      "[[0.0000000e+00 3.2782555e-07 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.0982278e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 5.4980268e-07 8.0866522e-01]\n",
      " [3.6631709e-36 3.6103960e-11 1.0000000e+00]]\n",
      "[[0.0000000e+00 9.9999809e-01 9.9999714e-01]\n",
      " [1.0000000e+00 5.2754581e-03 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 1.1920929e-07]\n",
      " [1.0000000e+00 1.1920929e-07 0.0000000e+00]\n",
      " [1.0000000e+00 3.8415194e-05 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.2584877e-07 0.0000000e+00]\n",
      " [0.0000000e+00 1.5536000e-06 1.0000000e+00]\n",
      " [1.0000000e+00 1.5270310e-04 0.0000000e+00]]\n",
      "[[1.0000000e+00 2.9802322e-08 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 6.4621290e-08 0.0000000e+00]\n",
      " [2.9117589e-35 1.0000000e+00 1.0000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999994e-01]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9997151e-01 9.9999583e-01]\n",
      " [0.0000000e+00 9.9999982e-01 2.6228130e-03]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 3.3925218e-10 0.0000000e+00]\n",
      " [1.0000000e+00 1.0375380e-10 0.0000000e+00]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 9.8256052e-01]\n",
      " [1.0000000e+00 3.5762787e-07 0.0000000e+00]\n",
      " [0.0000000e+00 9.9929065e-01 1.5795231e-05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 9.9999988e-01]\n",
      " [5.1325487e-20 1.0000000e+00 7.2999480e-19]\n",
      " [1.0000000e+00 3.5589195e-11 0.0000000e+00]]\n",
      "[[0.00000000e+00 1.14738941e-05 1.10298395e-04]\n",
      " [1.00000000e+00 4.76837158e-07 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 9.91724432e-01 5.63263893e-06]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 5.96046448e-08 0.00000000e+00]\n",
      " [0.00000000e+00 2.92062759e-06 1.00000000e+00]\n",
      " [1.00000000e+00 1.36876472e-13 0.00000000e+00]\n",
      " [1.00000000e+00 1.55927007e-11 0.00000000e+00]]\n",
      "[[0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 5.77032208e-01 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.41852506e-29 5.93736384e-15 1.00000000e+00]\n",
      " [1.00000000e+00 1.22594105e-11 0.00000000e+00]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 9.9952859e-01 0.0000000e+00]\n",
      " [0.0000000e+00 1.0000000e+00 3.0856572e-33]]\n",
      "Epoch 9, loss : 0.0000, val_loss : 1.2982, acc : 1.000, val_acc : 0.931\n",
      "test_acc : 0.989\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = y_train.shape[1]\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(x=X, n_input=n_input,\n",
    "                     n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_classes=n_classes)\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "#推定結果\n",
    "pred = tf.sigmoid(logits)\n",
    "# 推定結果が正しいか\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "                # エポックごとにループ\n",
    "                total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "                        # ミニバッチごとにループ\n",
    "                        sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "\n",
    "                        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "                        print(sess.run(pred, feed_dict={X: mini_batch_x}))\n",
    "                        #print(sess.run(correct_pred, feed_dict={X: mini_batch_x, Y: mini_batch_y}))\n",
    "\n",
    "                        total_loss += loss\n",
    "                        total_acc += acc\n",
    "                total_loss /= n_samples\n",
    "                total_acc /= n_samples\n",
    "                val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "                print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "        print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmaxでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 0 2 2 2 2 2 2 2]\n",
      "[1 0 1 0 0 1 0 0 1 0]\n",
      "[0 1 0 1 1 1 1 1 0 1]\n",
      "[0 1 1 1 1 1 1 1 0 0]\n",
      "[1 0 1 1 0 1 0 1 1 0]\n",
      "[1 0 1 1 1 1 0 1 0 0]\n",
      "[1 2 1 0 1 0 0 0 1 0]\n",
      "[0 2 2 2 2 2]\n",
      "Epoch 0, loss : 20.8562, val_loss : 12.2956, acc : 0.333, val_acc : 0.708\n",
      "[2 2 2 2 2 2 0 2 2 0]\n",
      "[2 2 2 0 0 2 0 2 2 2]\n",
      "[2 2 0 2 2 2 2 2 2 2]\n",
      "[2 0 2 0 0 2 0 0 2 0]\n",
      "[0 2 0 2 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 1 2 2 0 0]\n",
      "[1 0 1 1 0 1 0 1 1 0]\n",
      "[1 0 1 1 1 1 0 1 0 0]\n",
      "[1 1 1 0 1 0 0 0 1 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 1, loss : 0.1063, val_loss : 5.4166, acc : 1.000, val_acc : 0.667\n",
      "[2 1 2 2 1 2 0 2 2 0]\n",
      "[2 1 2 0 0 2 0 2 2 2]\n",
      "[2 2 0 2 2 1 2 2 2 2]\n",
      "[2 0 2 0 0 1 0 0 2 0]\n",
      "[0 2 0 2 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 2 2 2 0 0]\n",
      "[2 0 2 1 0 1 0 2 1 0]\n",
      "[1 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 2, loss : 0.0000, val_loss : 1.5133, acc : 1.000, val_acc : 0.833\n",
      "[2 1 2 2 1 2 0 1 2 0]\n",
      "[1 1 1 0 0 2 1 2 2 1]\n",
      "[1 2 0 2 1 1 1 1 2 1]\n",
      "[1 0 1 0 0 1 0 0 2 0]\n",
      "[0 1 0 1 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 1 2 2 0 0]\n",
      "[2 0 2 1 0 1 0 2 1 0]\n",
      "[2 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 3, loss : 0.0000, val_loss : 2.7195, acc : 1.000, val_acc : 0.917\n",
      "[2 1 2 2 1 2 0 2 2 0]\n",
      "[2 1 2 0 0 2 1 2 2 2]\n",
      "[2 2 0 2 1 1 1 1 2 2]\n",
      "[1 0 1 0 0 1 0 0 2 0]\n",
      "[0 1 0 1 2 2 2 2 0 1]\n",
      "[0 2 1 1 1 1 2 2 0 0]\n",
      "[1 0 1 1 0 1 0 2 1 0]\n",
      "[1 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 4, loss : 0.0000, val_loss : 0.5905, acc : 1.000, val_acc : 0.958\n",
      "[2 1 2 2 1 2 0 2 2 0]\n",
      "[2 1 2 0 0 2 1 2 2 2]\n",
      "[2 2 0 2 1 1 1 1 2 2]\n",
      "[1 0 1 0 0 1 0 0 2 0]\n",
      "[0 1 0 1 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 1 2 2 0 0]\n",
      "[2 0 1 1 0 1 0 2 1 0]\n",
      "[1 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 5, loss : 0.0000, val_loss : 0.4552, acc : 1.000, val_acc : 0.917\n",
      "[2 1 2 2 1 2 0 2 2 0]\n",
      "[1 1 1 0 0 2 1 2 2 2]\n",
      "[2 2 0 2 1 1 1 1 2 2]\n",
      "[1 0 1 0 0 1 0 0 2 0]\n",
      "[0 1 0 1 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 1 2 2 0 0]\n",
      "[2 0 2 1 0 1 0 2 1 0]\n",
      "[1 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 6, loss : 0.0000, val_loss : 0.7709, acc : 1.000, val_acc : 0.917\n",
      "[2 1 2 2 1 2 0 2 2 0]\n",
      "[2 1 1 0 0 2 1 2 2 2]\n",
      "[2 2 0 2 1 1 1 1 2 2]\n",
      "[1 0 1 0 0 1 0 0 2 0]\n",
      "[0 1 0 1 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 1 2 2 0 0]\n",
      "[2 0 1 1 0 1 0 2 1 0]\n",
      "[1 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 7, loss : 0.0000, val_loss : 0.5971, acc : 1.000, val_acc : 0.958\n",
      "[2 1 2 2 1 2 0 2 2 0]\n",
      "[2 1 1 0 0 2 1 2 2 2]\n",
      "[2 2 0 2 1 1 1 1 2 2]\n",
      "[2 0 1 0 0 1 0 0 2 0]\n",
      "[0 1 0 1 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 1 2 2 0 0]\n",
      "[2 0 2 1 0 1 0 2 1 0]\n",
      "[1 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 8, loss : 0.0000, val_loss : 0.6245, acc : 1.000, val_acc : 0.958\n",
      "[2 1 2 2 1 2 0 2 2 0]\n",
      "[1 1 1 0 0 2 1 2 2 2]\n",
      "[2 2 0 2 1 1 1 1 2 2]\n",
      "[1 0 1 0 0 1 0 0 2 0]\n",
      "[0 1 0 1 2 2 2 2 0 2]\n",
      "[0 2 1 1 2 1 2 2 0 0]\n",
      "[2 0 1 1 0 1 0 2 1 0]\n",
      "[1 0 1 1 1 2 0 2 0 0]\n",
      "[2 2 1 0 2 0 0 0 2 0]\n",
      "[0 2 1 1 1 1]\n",
      "Epoch 9, loss : 0.0000, val_loss : 0.5356, acc : 1.000, val_acc : 0.917\n",
      "test_acc : 1.000\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = y_train.shape[1]\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(x=X, n_input=n_input,\n",
    "                     n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_classes=n_classes)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits)\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "#推定結果(probability)\n",
    "proba = tf.nn.softmax(logits)\n",
    "#推定結果(label)\n",
    "pred = tf.argmax(proba, axis=1)\n",
    "# 推定結果が正しいか\n",
    "correct_pred = tf.equal(tf.argmax(Y, axis=1), pred)\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "                # エポックごとにループ\n",
    "                total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "                        # ミニバッチごとにループ\n",
    "                        sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "\n",
    "                        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "                        print(sess.run(pred, feed_dict={X: mini_batch_x}))\n",
    "                        #print(sess.run(correct_pred, feed_dict={X: mini_batch_x, Y: mini_batch_y}))\n",
    "\n",
    "                        total_loss += loss\n",
    "                        total_acc += acc\n",
    "                total_loss /= n_samples\n",
    "                total_acc /= n_samples\n",
    "                val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "                print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "        print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmaxは各列の合計が1になるような計算のため、one-hot vectorの各列に対して最も確率が高いもののみ1となる。確率が(0.35, 0.12, 0.53)の場合、判定は(0, 0, 1)。対して、Sigmoidでも推定できた。Sigmoidの場合yの確率が0.5以上で1と判定されるが、one-hot vectorの各列に対して独立に扱っているため複数の列で1になりうるし、全ての列で0にもなりうる。学習が進むと結果的に1つの列でのみ1に落ち着く傾向にあるが、特に学習序盤だと複数のフラグが1になったり全ての列で0となっているることもあるとわかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】House Pricesのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = '../../../diveintocode-term1/sprint/sprint3/train.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#scaling\\nfrom sklearn.preprocessing import StandardScaler\\n#generate instance\\nscaler = StandardScaler()\\n\\n#fit with train\\nscaler.fit(X_train)\\n#transform train, val, test data with fitted scaler\\nX_train = scaler.transform(X_train)\\nX_val = scaler.transform(X_val)\\nX_test = scaler.transform(X_test)\\n\\n\\n#fit with train\\nscaler.fit(y_train)\\n#transform train, val, test data with fitted scaler\\ny_train = scaler.transform(y_train)\\ny_val = scaler.transform(y_val)\\ny_test = scaler.transform(y_test)\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = data.loc[:, [\"SalePrice\"]]\n",
    "#pandas -> ndarray\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "#logとって歪度を修正\n",
    "y = np.log(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split data (all -> train, test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#split data (train -> train, val)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "#y scaling (min: 0, max: 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#generate instance\n",
    "scaler_min_max = MinMaxScaler()\n",
    "\n",
    "y_max = np.max(y)\n",
    "y_min = np.min(y)\n",
    "#fit with train\n",
    "scaler_min_max.fit(y_train)\n",
    "#transform train, val, test data with fitted scaler\n",
    "y_train = scaler_min_max.transform(y_train)\n",
    "y_val = scaler_min_max.transform(y_val)\n",
    "y_test = scaler_min_max.transform(y_test)\n",
    "\n",
    "\n",
    "#X scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#generate instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit with train\n",
    "scaler.fit(X_train)\n",
    "#transform train, val, test data with fitted scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#generate instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit with train\n",
    "scaler.fit(X_train)\n",
    "#transform train, val, test data with fitted scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#fit with train\n",
    "scaler.fit(y_train)\n",
    "#transform train, val, test data with fitted scaler\n",
    "y_train = scaler.transform(y_train)\n",
    "y_val = scaler.transform(y_val)\n",
    "y_test = scaler.transform(y_test)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_net(x, n_input, n_hidden1, n_hidden2, n_classes):\n",
    "    \"\"\"\n",
    "    3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.matmul(x, weights['w1']) + biases['b1']\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    layer_2 = tf.matmul(layer_1, weights['w2']) + biases['b2']\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.0523, val_loss: 0.0078\n",
      "Epoch 1, loss: 0.0066, val_loss: 0.0057\n",
      "Epoch 2, loss: 0.0058, val_loss: 0.0053\n",
      "Epoch 3, loss: 0.0056, val_loss: 0.0052\n",
      "Epoch 4, loss: 0.0055, val_loss: 0.0051\n",
      "Epoch 5, loss: 0.0054, val_loss: 0.0050\n",
      "Epoch 6, loss: 0.0053, val_loss: 0.0050\n",
      "Epoch 7, loss: 0.0053, val_loss: 0.0050\n",
      "Epoch 8, loss: 0.0052, val_loss: 0.0049\n",
      "Epoch 9, loss: 0.0052, val_loss: 0.0049\n",
      "Epoch 10, loss: 0.0052, val_loss: 0.0049\n",
      "Epoch 11, loss: 0.0051, val_loss: 0.0049\n",
      "Epoch 12, loss: 0.0051, val_loss: 0.0049\n",
      "Epoch 13, loss: 0.0051, val_loss: 0.0049\n",
      "Epoch 14, loss: 0.0051, val_loss: 0.0049\n",
      "Epoch 15, loss: 0.0050, val_loss: 0.0049\n",
      "Epoch 16, loss: 0.0050, val_loss: 0.0049\n",
      "Epoch 17, loss: 0.0050, val_loss: 0.0048\n",
      "Epoch 18, loss: 0.0050, val_loss: 0.0048\n",
      "Epoch 19, loss: 0.0050, val_loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "#hyper parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "n_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes= y_train.shape[1]\n",
    "\n",
    "#計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "#trainのミニバッチイテレータ\n",
    "mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "#network構造の読み込み\n",
    "logits = reg_net(x=X, n_input=n_input,\n",
    "                     n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_classes=n_classes)\n",
    "\n",
    "#prediction\n",
    "pred = tf.nn.sigmoid(logits)\n",
    "\n",
    "#目的関数\n",
    "mse  = tf.reduce_mean(tf.square(pred - Y))\n",
    "\n",
    "#最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "#最適化\n",
    "train_op = optimizer.minimize(mse)\n",
    "\n",
    "#variable初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        loss_log = {\"training\": [], \"validation\": []}\n",
    "        for epoch in range(n_epochs):\n",
    "                total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "                total_loss = 0\n",
    "                for i, (mini_x, mini_y) in enumerate(mini_batch_train):\n",
    "                        sess.run(train_op, feed_dict={X:mini_x, Y:mini_y})\n",
    "                        loss = sess.run(mse, feed_dict={X:mini_x, Y:mini_y})\n",
    "                        total_loss += loss\n",
    "                        \n",
    "                total_loss /= total_batch\n",
    "                val_loss = sess.run(mse,  feed_dict={X:X_val, Y:y_val})\n",
    "                y_pred = sess.run(pred, feed_dict={X:X_test}) \n",
    "                loss_log[\"training\"].append(total_loss)\n",
    "                loss_log[\"validation\"].append(val_loss)\n",
    "                print(\"Epoch %d, loss: %.4f, val_loss: %.4f\" % (epoch, total_loss, val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2b8dd668>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "axes.plot(loss_log[\"training\"], label=\"training\")\n",
    "axes.plot(loss_log[\"validation\"], label=\"validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "axes.scatter(np.exp(y_test*(y_max - y_min) + y_min), np.exp(y_pred*(y_max - y_min) + y_min), label='predicted');\n",
    "axes.plot(np.exp(y_test*(y_max - y_min) + y_min), np.exp(y_test*(y_max - y_min) + y_min), label='actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】MNISTのモデルを作成\n",
    "ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n",
    "\n",
    "3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n",
    "\n",
    "スクラッチで実装したモデルの再現を目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#yをone-hot化\n",
    "eye = np.eye(len(np.unique(y_train)))\n",
    "y_train = eye[y_train]\n",
    "y_test = eye[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "X_train = X_train.reshape(-1, X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(-1, X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "#split into train, val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) \n",
    "print(X_val.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_net(x, n_input, n_hidden1, n_hidden2, n_classes):\n",
    "    \"\"\"\n",
    "    3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 6961.4014, val_loss : 9005.8369, acc : 0.850, val_acc : 0.896\n",
      "Epoch 1, loss : 0.0000, val_loss : 5739.1973, acc : 1.000, val_acc : 0.920\n",
      "Epoch 2, loss : 0.0000, val_loss : 4735.3701, acc : 1.000, val_acc : 0.929\n",
      "Epoch 3, loss : 0.0000, val_loss : 4002.5537, acc : 1.000, val_acc : 0.936\n",
      "Epoch 4, loss : 0.0000, val_loss : 3925.8540, acc : 1.000, val_acc : 0.937\n",
      "Epoch 5, loss : 0.0000, val_loss : 3537.3333, acc : 1.000, val_acc : 0.942\n",
      "Epoch 6, loss : 0.0000, val_loss : 3274.8242, acc : 1.000, val_acc : 0.948\n",
      "Epoch 7, loss : 0.0000, val_loss : 3340.9619, acc : 1.000, val_acc : 0.948\n",
      "Epoch 8, loss : 0.0000, val_loss : 3250.4583, acc : 1.000, val_acc : 0.950\n",
      "Epoch 9, loss : 0.0000, val_loss : 3113.4939, acc : 1.000, val_acc : 0.952\n",
      "test_acc : 0.953\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#hyper parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 20\n",
    "n_epochs = 10\n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 200\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes= y_train.shape[1]\n",
    "\n",
    "#計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "#trainのミニバッチイテレータ\n",
    "mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "#network構造の読み込み\n",
    "\n",
    "logits = mnist_net(x=X, n_input=n_input,\n",
    "                     n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_classes=n_classes)\n",
    "\n",
    "#loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits)\n",
    "\n",
    "#目的関数\n",
    "loss_to_optimize  = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "#最適化\n",
    "train_op = optimizer.minimize(loss_to_optimize)\n",
    "\n",
    "#prediction(probability)\n",
    "proba = tf.nn.softmax(logits)\n",
    "\n",
    "#prediction(value)\n",
    "pred = tf.argmax(proba, axis=1)\n",
    "\n",
    "#正解true不正解false\n",
    "correct_pred = tf.equal(tf.argmax(Y, axis=1), pred)\n",
    "\n",
    "#Accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#variable初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        loss_log = {\"training\": [], \"validation\": []}\n",
    "        for epoch in range(n_epochs):\n",
    "                total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                for i, (mini_x, mini_y) in enumerate(mini_batch_train):\n",
    "                        sess.run(train_op, feed_dict={X:mini_x, Y:mini_y})\n",
    "                        loss, acc = sess.run([loss_to_optimize, accuracy], feed_dict={X: mini_x, Y: mini_y})\n",
    "                        total_loss += loss\n",
    "                        total_acc += acc\n",
    "                \n",
    "                total_loss /= total_batch\n",
    "                total_acc /= total_batch\n",
    "                \n",
    "                val_loss, val_acc = sess.run([loss_to_optimize, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "\n",
    "                loss_log[\"training\"].append(total_loss)\n",
    "                loss_log[\"validation\"].append(val_loss)\n",
    "                print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "        print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb368187f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "axes.plot(loss_log[\"training\"], label=\"training\")\n",
    "axes.plot(loss_log[\"validation\"], label=\"validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
