{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint0 授業前課題\n",
    "# 機械学習スクラッチ入門\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはスクラッチの練習として、scikit-learnのtrain_test_splitを自作してみましょう。Jupyter Notebookでコーディングを進め、完成後はpyファイルとします。utilsディレクトリの中にsplit.pyを作ってください。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.20.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyファイルを読み込むためにpathを追加\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#pathが直下に無いのでutilへのpathを追加\n",
    "str = \"/Users/ohmori/diveintocode-ml/diveintocode-term1/ml-scratch/utils\"\n",
    "\n",
    "#strがsys.pathになければ追加\n",
    "if str not in sys.path:\n",
    "    sys.path.append(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/ohmori/anaconda3/lib/python36.zip', '/Users/ohmori/anaconda3/lib/python3.6', '/Users/ohmori/anaconda3/lib/python3.6/lib-dynload', '', '/Users/ohmori/anaconda3/lib/python3.6/site-packages', '/Users/ohmori/anaconda3/lib/python3.6/site-packages/aeosa', '/Users/ohmori/anaconda3/lib/python3.6/site-packages/IPython/extensions', '/Users/ohmori/.ipython', '/Users/ohmori/diveintocode-ml/diveintocode-term1/ml-scratch/utils']\n"
     ]
    }
   ],
   "source": [
    "#path追加の確認\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split.pyからtrain_test_splitのmethodをimport \n",
    "from split import  train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成したpyファイルは[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term1/ml-scratch/utils/split.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#動作確認\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6],\n",
    "    [7, 8]\n",
    "])\n",
    "\n",
    "y = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [5 6]\n",
      " [7 8]] \n",
      "\n",
      "[[1 2]] \n",
      "\n",
      "[2 3 4] \n",
      "\n",
      "[1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_train, '\\n')\n",
    "print(X_test, '\\n')\n",
    "print(y_train, '\\n')\n",
    "print(y_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類パイプラインの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類は3種類の手法を扱います。pyファイルで実行できる分類のパイプラインを作成してください。\n",
    "\n",
    "* ロジスティック回帰<br>\n",
    "* SVM<br>\n",
    "* 決定木<br>\n",
    "\n",
    "データセットは3種類用意します。\n",
    "\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "\n",
    "[sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "* virgicolorとvirginica\n",
    "\n",
    "また、残り2つは可視化が可能な特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "print(dataset.keys())\n",
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "   species\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "\n",
    "import pandas as pd\n",
    "#import features\n",
    "X = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "\n",
    "#import target value\n",
    "y = pd.DataFrame(dataset.target, columns = {'species'})\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate x and y\n",
    "df = pd.concat((X, y), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only versicolor and virginica\n",
    "#drop setosa rows(label: 0)\n",
    "\n",
    "setosa_row = df[df['species'] == 0].index\n",
    "df = df.drop(setosa_row, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "50                7.0               3.2                4.7               1.4   \n",
       "51                6.4               3.2                4.5               1.5   \n",
       "52                6.9               3.1                4.9               1.5   \n",
       "53                5.5               2.3                4.0               1.3   \n",
       "54                6.5               2.8                4.6               1.5   \n",
       "\n",
       "    species  \n",
       "50        1  \n",
       "51        1  \n",
       "52        1  \n",
       "53        1  \n",
       "54        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split import  train_test_split\n",
    "#split arrays into two (train, test)\n",
    "#shuffling is True by default\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(df.iloc[:, :4]), np.array(df.iloc[:, 4]), train_size=3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4)\n",
      "(25, 4)\n",
      "(75,)\n",
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "#confirm if correctly split\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit, Estimate and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyファイルは[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term1/sprint/sprint0/modules/Classification.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        25\n",
      "   macro avg       0.95      0.97      0.96        25\n",
      "weighted avg       0.96      0.96      0.96        25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohmori/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Regression.pyからLogisticRegressionをインポート\n",
    "from modules.Classification import LogReg\n",
    "#Regression.pyからSVClasisfierをインポート\n",
    "from modules.Classification import SVClassifier\n",
    "#Regression.pyからDecisionTreeClassifierをインポート\n",
    "from modules.Classification import DTClassifier\n",
    "\n",
    "\n",
    "LogReg(X_train, X_test, y_train, y_test);\n",
    "SVClassifier(X_train, X_test, y_train, y_test);\n",
    "DTClassifier(X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split import  train_test_split\n",
    "#split arrays into two (train, test)\n",
    "#shuffling is True by default\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=3/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit, Estimate and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        58\n",
      "           1       1.00      1.00      1.00        67\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       125\n",
      "   macro avg       1.00      1.00      1.00       125\n",
      "weighted avg       1.00      1.00      1.00       125\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        58\n",
      "           1       1.00      1.00      1.00        67\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       125\n",
      "   macro avg       1.00      1.00      1.00       125\n",
      "weighted avg       1.00      1.00      1.00       125\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        58\n",
      "           1       1.00      1.00      1.00        67\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       125\n",
      "   macro avg       1.00      1.00      1.00       125\n",
      "weighted avg       1.00      1.00      1.00       125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohmori/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LogReg(X_train, X_test, y_train, y_test);\n",
    "SVClassifier(X_train, X_test, y_train, y_test);\n",
    "DTClassifier(X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シンプルデータセット2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split import  train_test_split\n",
    "#split arrays into two (train, test)\n",
    "#shuffling is True by default\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=3/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit, Estimate and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.67      0.44         3\n",
      "           1       0.75      0.43      0.55         7\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        10\n",
      "   macro avg       0.54      0.55      0.49        10\n",
      "weighted avg       0.62      0.50      0.52        10\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         3\n",
      "           1       1.00      0.14      0.25         7\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        10\n",
      "   macro avg       0.67      0.57      0.38        10\n",
      "weighted avg       0.80      0.40      0.33        10\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.67      0.44         3\n",
      "           1       0.75      0.43      0.55         7\n",
      "\n",
      "   micro avg       0.50      0.50      0.50        10\n",
      "   macro avg       0.54      0.55      0.49        10\n",
      "weighted avg       0.62      0.50      0.52        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohmori/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LogReg(X_train, X_test, y_train, y_test);\n",
    "SVClassifier(X_train, X_test, y_train, y_test);\n",
    "DTClassifier(X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰パイプラインの作成\n",
    "回帰は1種類を扱います。pyファイルで実行できる回帰のパイプラインを作成してください。\n",
    "\n",
    "* 線形回帰\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House Pricesコンペティション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read csv file to get data frame\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "#split into features X and target y\n",
    "X = df.loc[:, [\"YearBuilt\", \"GrLivArea\"]]\n",
    "df['SalePriceLog'] = np.log(df[\"SalePrice\"])\n",
    "y = df.loc[:, ['SalePriceLog']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YearBuilt  GrLivArea\n",
      "0       2003       1710\n",
      "1       1976       1262\n",
      "2       2001       1786\n",
      "3       1915       1717\n",
      "4       2000       2198 \n",
      "\n",
      "   SalePriceLog\n",
      "0     12.247694\n",
      "1     12.109011\n",
      "2     12.317167\n",
      "3     11.849398\n",
      "4     12.429216\n"
     ]
    }
   ],
   "source": [
    "#confirm datra\n",
    "print(X.head(), \"\\n\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=3/4, test_size=1/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit, Estimate and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyファイルは[こちら](https://github.com/ohmorimori/diveintocode-ml/blob/master/diveintocode-term1/sprint/sprint0/modules/Regression.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score R^2 0.6893987992204424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohmori/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/ohmori/anaconda3/lib/python3.6/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/ohmori/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:331: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/Users/ohmori/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:511: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#Regression.pyからLinearRegをインポート\n",
    "from modules.Regression import LinearReg\n",
    "\n",
    "LinearReg(X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
